{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Direct Preference Optimization (DPO) Training on Google Colab\n",
    "\n",
    "This notebook trains a DPO model on the Anthropic HH dataset using free Colab GPUs.\n",
    "\n",
    "**Steps:**\n",
    "1. Setup environment and install dependencies\n",
    "2. Upload/clone your code\n",
    "3. Train SFT baseline\n",
    "4. Train DPO model\n",
    "5. Evaluate and download results\n",
    "\n",
    "**Runtime:** Make sure to use **GPU runtime** (Runtime → Change runtime type → GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  No GPU detected. Go to Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload-code"
   },
   "source": [
    "## 2. Upload Your Code\n",
    "\n",
    "**Option A: Upload ZIP file**\n",
    "- Compress your `dpo/` folder into `dpo.zip`\n",
    "- Upload using the cell below\n",
    "\n",
    "**Option B: Clone from GitHub** (if you've pushed to GitHub)\n",
    "- Uncomment and run the git clone cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-zip"
   },
   "outputs": [],
   "source": "# Option A: Upload ZIP file\nfrom google.colab import files\nimport zipfile\nimport os\n\nprint(\"Upload your dpo.zip file...\")\nuploaded = files.upload()\n\n# Extract directly to /content/dpo\nfor filename in uploaded.keys():\n    if filename.endswith('.zip'):\n        with zipfile.ZipFile(filename, 'r') as zip_ref:\n            # Extract to /content/dpo\n            zip_ref.extractall('/content/dpo')\n        print(f\"✓ Extracted {filename}\")\n\n# Change to project directory\n%cd /content/dpo\n\n# Verify we're in the right place\n!ls -la"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-github"
   },
   "outputs": [],
   "source": "# Option B: Clone from GitHub\n# Replace YOUR_USERNAME with your GitHub username\n!git clone https://github.com/YOUR_USERNAME/dpo.git /content/dpo\n%cd /content/dpo\n\n# Verify we're in the right place\n!ls -la"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pip-install"
   },
   "outputs": [],
   "source": "# Install requirements\n!pip install -q -r requirements.txt\n\n# Add project to Python path\nimport sys\nsys.path.insert(0, '/content/dpo')\n\n# Verify installation\nimport transformers\nimport datasets\nprint(f\"✓ transformers {transformers.__version__}\")\nprint(f\"✓ datasets {datasets.__version__}\")\nprint(\"✓ Python path configured\")\nprint(\"\\n✓ All dependencies installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sanity-check"
   },
   "source": [
    "## 4. Run Sanity Checks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-sanity"
   },
   "outputs": [],
   "source": "# Ensure we're in the right directory and Python path is set\nimport sys\nimport os\n\nos.chdir('/content/dpo')\nif '/content/dpo' not in sys.path:\n    sys.path.insert(0, '/content/dpo')\n\n# Run sanity checks to verify everything works\n!python tests/test_sanity.py"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 5. Configure Training\n",
    "\n",
    "Adjust these settings based on your Colab GPU:\n",
    "- **T4 (free)**: Use configs as-is or reduce batch size to 2\n",
    "- **V100/A100 (Pro)**: Can increase batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-vars"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "USE_DEBUG_MODE = True  # Set to False for full training\n",
    "NUM_TRAIN_SAMPLES = 1000 if not USE_DEBUG_MODE else None  # Limit samples for faster training\n",
    "\n",
    "# Paths\n",
    "SFT_OUTPUT = \"/content/outputs/sft\"\n",
    "DPO_OUTPUT = \"/content/outputs/dpo\"\n",
    "\n",
    "print(f\"Debug mode: {USE_DEBUG_MODE}\")\n",
    "print(f\"SFT output: {SFT_OUTPUT}\")\n",
    "print(f\"DPO output: {DPO_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-sft"
   },
   "source": [
    "## 6. Train SFT Baseline\n",
    "\n",
    "First, we train a supervised fine-tuned model on the chosen responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sft-training"
   },
   "outputs": [],
   "source": "# Ensure correct directory\nimport os\nos.chdir('/content/dpo')\n\n# Train SFT model\nconfig = \"configs/debug.yaml\" if USE_DEBUG_MODE else \"configs/sft.yaml\"\ndebug_flag = \"--debug\" if USE_DEBUG_MODE else \"\"\n\n!python scripts/train_sft.py \\\n    --config {config} \\\n    --output_dir {SFT_OUTPUT} \\\n    {debug_flag}"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-dpo"
   },
   "source": [
    "## 7. Train DPO Model\n",
    "\n",
    "Now we train DPO using the SFT model as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpo-training"
   },
   "outputs": [],
   "source": "# Ensure correct directory\nimport os\nos.chdir('/content/dpo')\n\n# Train DPO model\nconfig = \"configs/debug.yaml\" if USE_DEBUG_MODE else \"configs/dpo.yaml\"\ndebug_flag = \"--debug\" if USE_DEBUG_MODE else \"\"\nsft_path = f\"{SFT_OUTPUT}/final\"\n\n!python scripts/train_dpo.py \\\n    --config {config} \\\n    --sft_model_path {sft_path} \\\n    --output_dir {DPO_OUTPUT} \\\n    {debug_flag}"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## 8. Evaluate Models\n",
    "\n",
    "Compare the base model, SFT, and DPO models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-eval"
   },
   "outputs": [],
   "source": "# Ensure correct directory\nimport os\nos.chdir('/content/dpo')\n\n# Evaluate all models\n!python scripts/evaluate.py \\\n    --reference_model gpt2 \\\n    --sft_model {SFT_OUTPUT}/final \\\n    --dpo_model {DPO_OUTPUT}/final \\\n    --output_file /content/outputs/results.json \\\n    --num_samples 500 \\\n    --num_generation_samples 5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-results"
   },
   "source": [
    "## 9. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# Display evaluation results\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('/content/outputs/results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Convert to DataFrame for nice display\n",
    "df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(df.to_string())\n",
    "\n",
    "# Display sample generations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE GENERATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open('/content/outputs/generation_samples.json', 'r') as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "for i, sample in enumerate(samples[:3]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Prompt: {sample['prompt'][:100]}...\")\n",
    "    print(f\"\\nReference: {sample.get('reference', 'N/A')[:200]}...\")\n",
    "    print(f\"\\nSFT: {sample.get('sft', 'N/A')[:200]}...\")\n",
    "    print(f\"\\nDPO: {sample.get('dpo', 'N/A')[:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 10. Download Trained Models\n",
    "\n",
    "Download your trained models to use locally or share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip-models"
   },
   "outputs": [],
   "source": [
    "# Zip the outputs\n",
    "!zip -r /content/dpo_models.zip /content/outputs/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('/content/dpo_models.zip')\n",
    "\n",
    "print(\"✓ Models packaged and downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitoring"
   },
   "source": [
    "## 11. Monitor Training (Optional)\n",
    "\n",
    "If you enabled Weights & Biases logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wandb-setup"
   },
   "outputs": [],
   "source": [
    "# Setup Weights & Biases (optional)\n",
    "# !pip install -q wandb\n",
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "# Then modify your config to enable wandb:\n",
    "# logging:\n",
    "#   use_wandb: true\n",
    "#   wandb_project: \"dpo-colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## Tips for Colab Training\n",
    "\n",
    "### GPU Runtime\n",
    "- **Free tier**: T4 GPU (16GB), limited to ~12 hours\n",
    "- **Colab Pro**: Better GPUs (V100/A100), longer sessions\n",
    "\n",
    "### Avoid Disconnects\n",
    "```javascript\n",
    "// Run this in browser console to keep session alive\n",
    "function KeepAlive() {\n",
    "    document.querySelector(\"colab-connect-button\").click();\n",
    "}\n",
    "setInterval(KeepAlive, 60000);\n",
    "```\n",
    "\n",
    "### Save Checkpoints to Google Drive\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Then set output_dir to /content/drive/MyDrive/dpo_outputs\n",
    "```\n",
    "\n",
    "### Reduce Memory Usage\n",
    "If you hit OOM errors:\n",
    "- Reduce `per_device_batch_size` to 2 or 1\n",
    "- Increase `gradient_accumulation_steps` to maintain effective batch size\n",
    "- Reduce `max_length` to 256 or 128\n",
    "- Enable gradient checkpointing (already on by default)\n",
    "\n",
    "### Speed Up Training\n",
    "- Use smaller model: `model_name_or_path: \"gpt2\"` (124M) instead of larger variants\n",
    "- Reduce dataset size: Add `--debug` flag or limit `num_samples`\n",
    "- Use fewer epochs: Set `num_epochs: 1`\n",
    "\n",
    "### Expected Training Times (T4 GPU)\n",
    "- **Debug mode** (~100 samples): 5-10 minutes per model\n",
    "- **Small training** (~1000 samples): 30-60 minutes per model\n",
    "- **Full training** (~160k samples): 8-12 hours for SFT + DPO\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**\"No module named 'src'\"**\n",
    "- Make sure you're in the `/content/dpo` directory\n",
    "- Run: `%cd /content/dpo`\n",
    "\n",
    "**\"CUDA out of memory\"**\n",
    "- Reduce batch size: `--batch_size 2`\n",
    "- Use debug config: `--config configs/debug.yaml`\n",
    "\n",
    "**\"Session crashed\"**\n",
    "- Your training is too long for free tier\n",
    "- Reduce dataset size or use debug mode\n",
    "- Consider Colab Pro for longer sessions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}