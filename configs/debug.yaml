# Debug Configuration - Small dataset for fast testing

model:
  model_name_or_path: "gpt2"
  use_gradient_checkpointing: false  # Faster for debugging
  torch_dtype: "float32"  # More stable for debugging

data:
  dataset_name: "Anthropic/hh-rlhf"
  max_length: 256  # Shorter for faster processing
  max_prompt_length: 128
  train_split: "train"
  val_ratio: 0.2  # Larger val set for debugging
  test_ratio: 0.1
  num_proc: 2

training:
  learning_rate: 2.0e-4
  num_epochs: 2
  per_device_batch_size: 2
  gradient_accumulation_steps: 2
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  fp16: false  # Disabled for debugging
  logging_steps: 1  # Log every step
  eval_steps: 10  # Evaluate frequently
  save_steps: 50
  save_total_limit: 2
  seed: 42

# DPO-specific (for DPO debug mode)
beta: 0.1
loss_type: "sigmoid"
label_smoothing: 0.0

output_dir: "outputs/debug"

logging:
  log_level: "debug"
  use_wandb: false
  wandb_project: "dpo-hh"
  wandb_run_name: "debug"
